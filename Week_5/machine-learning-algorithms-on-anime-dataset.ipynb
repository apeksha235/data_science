{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom matplotlib import pyplot as plt\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error, r2_score, accuracy_score\nfrom sklearn.metrics import classification_report, confusion_matrix\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.ensemble import RandomForestRegressor, ExtraTreesRegressor, AdaBoostRegressor, BaggingRegressor, GradientBoostingRegressor\nfrom sklearn.datasets import make_regression\nfrom sklearn.linear_model import  TheilSenRegressor, RANSACRegressor, HuberRegressor, PassiveAggressiveRegressor, SGDRegressor\nfrom sklearn.gaussian_process import GaussianProcessRegressor\nfrom sklearn.svm import SVR, NuSVR\nfrom sklearn.neighbors import KNeighborsRegressor\nimport lightgbm as lgb\nimport xgboost as xgb\nfrom catboost import CatBoostRegressor\nfrom sklearn.kernel_ridge import KernelRidge\nfrom sklearn.cluster import KMeans","metadata":{"execution":{"iopub.status.busy":"2021-12-20T19:40:15.428628Z","iopub.execute_input":"2021-12-20T19:40:15.430280Z","iopub.status.idle":"2021-12-20T19:40:15.440745Z","shell.execute_reply.started":"2021-12-20T19:40:15.430203Z","shell.execute_reply":"2021-12-20T19:40:15.439884Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"markdown","source":"### This is the Top 100 anime rating dataset ","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv('../input/top-100-anime-dataset-ratings/final_anime_dataset.csv')\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2021-12-20T19:40:15.442416Z","iopub.execute_input":"2021-12-20T19:40:15.442983Z","iopub.status.idle":"2021-12-20T19:40:15.489271Z","shell.execute_reply.started":"2021-12-20T19:40:15.442928Z","shell.execute_reply":"2021-12-20T19:40:15.488087Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"markdown","source":"- I have used ```No. of episodes```, ```TV show``` and the rest of the Genre categories as the input features, with ```Rating``` as the output variable.","metadata":{}},{"cell_type":"markdown","source":"- Here I have created a function ```reg_func``` to make it easier to implement the machine learning algorithms","metadata":{}},{"cell_type":"code","source":"X = df[['TV show','Genre: magic', 'Genre: adventure', 'Genre: psychological',\n       'Genre: comedy', 'Genre: drama', 'Genre: romance', 'Genre: mystery',\n       'Genre: action', 'Genre: fantasy']]\nY = df['Rating']\nx_train, x_test,y_train,y_test = train_test_split(X,Y,test_size =0.2)\ndef reg_func(model):\n       model.fit(x_train,y_train)\n       y_pred=model.predict(x_test)\n       score=mean_squared_error(y_test,y_pred)\n       print('Mean Squared Error: '+str(score))\n","metadata":{"execution":{"iopub.status.busy":"2021-12-20T19:40:15.490709Z","iopub.execute_input":"2021-12-20T19:40:15.491127Z","iopub.status.idle":"2021-12-20T19:40:15.501861Z","shell.execute_reply.started":"2021-12-20T19:40:15.491095Z","shell.execute_reply":"2021-12-20T19:40:15.501126Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"markdown","source":"- ### Linear Regression","metadata":{}},{"cell_type":"code","source":"\nmodel = LinearRegression()\nreg_func(model)\n","metadata":{"execution":{"iopub.status.busy":"2021-12-20T19:40:15.503201Z","iopub.execute_input":"2021-12-20T19:40:15.503632Z","iopub.status.idle":"2021-12-20T19:40:15.519741Z","shell.execute_reply.started":"2021-12-20T19:40:15.503600Z","shell.execute_reply":"2021-12-20T19:40:15.518816Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"markdown","source":"- ### TheilSen Regressor","metadata":{}},{"cell_type":"code","source":"model = TheilSenRegressor()\nreg_func(model)","metadata":{"execution":{"iopub.status.busy":"2021-12-20T19:40:15.522534Z","iopub.execute_input":"2021-12-20T19:40:15.523225Z","iopub.status.idle":"2021-12-20T19:40:16.256383Z","shell.execute_reply.started":"2021-12-20T19:40:15.523174Z","shell.execute_reply":"2021-12-20T19:40:16.255418Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"markdown","source":"- ### RANSAC Regressor","metadata":{}},{"cell_type":"code","source":"model = RANSACRegressor()\nreg_func(model)","metadata":{"execution":{"iopub.status.busy":"2021-12-20T19:40:16.257856Z","iopub.execute_input":"2021-12-20T19:40:16.258071Z","iopub.status.idle":"2021-12-20T19:40:16.329106Z","shell.execute_reply.started":"2021-12-20T19:40:16.258045Z","shell.execute_reply":"2021-12-20T19:40:16.328223Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"markdown","source":"- ### Huber Regressor","metadata":{}},{"cell_type":"code","source":"model = HuberRegressor()\nreg_func(model)","metadata":{"execution":{"iopub.status.busy":"2021-12-20T19:40:16.330813Z","iopub.execute_input":"2021-12-20T19:40:16.331710Z","iopub.status.idle":"2021-12-20T19:40:16.357503Z","shell.execute_reply.started":"2021-12-20T19:40:16.331657Z","shell.execute_reply":"2021-12-20T19:40:16.356019Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"markdown","source":"- ### Passive Aggressive Regressor","metadata":{}},{"cell_type":"code","source":"model=PassiveAggressiveRegressor()\nreg_func(model)","metadata":{"execution":{"iopub.status.busy":"2021-12-20T19:40:16.358753Z","iopub.execute_input":"2021-12-20T19:40:16.359056Z","iopub.status.idle":"2021-12-20T19:40:16.369827Z","shell.execute_reply.started":"2021-12-20T19:40:16.359023Z","shell.execute_reply":"2021-12-20T19:40:16.368512Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"markdown","source":"- ### Gaussian Process Regressor","metadata":{}},{"cell_type":"code","source":"model = GaussianProcessRegressor(normalize_y=True)\nreg_func(model)","metadata":{"execution":{"iopub.status.busy":"2021-12-20T19:40:16.371174Z","iopub.execute_input":"2021-12-20T19:40:16.371501Z","iopub.status.idle":"2021-12-20T19:40:16.397125Z","shell.execute_reply.started":"2021-12-20T19:40:16.371451Z","shell.execute_reply":"2021-12-20T19:40:16.396218Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"markdown","source":"- ### Support Vector Machine","metadata":{}},{"cell_type":"code","source":"model = SVR()\nreg_func(model)","metadata":{"execution":{"iopub.status.busy":"2021-12-20T19:40:16.401498Z","iopub.execute_input":"2021-12-20T19:40:16.401955Z","iopub.status.idle":"2021-12-20T19:40:16.416200Z","shell.execute_reply.started":"2021-12-20T19:40:16.401897Z","shell.execute_reply":"2021-12-20T19:40:16.414881Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"markdown","source":"- ### NU Support Vector Regression","metadata":{}},{"cell_type":"code","source":"model = NuSVR()\nreg_func(model)","metadata":{"execution":{"iopub.status.busy":"2021-12-20T19:40:16.417890Z","iopub.execute_input":"2021-12-20T19:40:16.418287Z","iopub.status.idle":"2021-12-20T19:40:16.438998Z","shell.execute_reply.started":"2021-12-20T19:40:16.418238Z","shell.execute_reply":"2021-12-20T19:40:16.437533Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"markdown","source":"- ### KNNeighbours as Regressor","metadata":{}},{"cell_type":"code","source":"model= KNeighborsRegressor(n_neighbors=5)\nreg_func(model)","metadata":{"execution":{"iopub.status.busy":"2021-12-20T19:40:57.299894Z","iopub.execute_input":"2021-12-20T19:40:57.300211Z","iopub.status.idle":"2021-12-20T19:40:57.313034Z","shell.execute_reply.started":"2021-12-20T19:40:57.300174Z","shell.execute_reply":"2021-12-20T19:40:57.312128Z"},"trusted":true},"execution_count":48,"outputs":[]},{"cell_type":"markdown","source":"- ### Stochastic Gradient Descent","metadata":{}},{"cell_type":"code","source":"model= SGDRegressor(n_iter_no_change=750)\nreg_func(model)","metadata":{"execution":{"iopub.status.busy":"2021-12-20T19:41:15.185565Z","iopub.execute_input":"2021-12-20T19:41:15.185829Z","iopub.status.idle":"2021-12-20T19:41:15.203492Z","shell.execute_reply.started":"2021-12-20T19:41:15.185802Z","shell.execute_reply":"2021-12-20T19:41:15.202534Z"},"trusted":true},"execution_count":50,"outputs":[]},{"cell_type":"markdown","source":"- ### Kernal Ridge Regression","metadata":{}},{"cell_type":"code","source":"model= KernelRidge(alpha=0.6, kernel='polynomial', degree=2, coef0=2.5)\nreg_func(model)","metadata":{"execution":{"iopub.status.busy":"2021-12-20T19:40:16.519329Z","iopub.execute_input":"2021-12-20T19:40:16.520396Z","iopub.status.idle":"2021-12-20T19:40:16.536274Z","shell.execute_reply.started":"2021-12-20T19:40:16.520342Z","shell.execute_reply":"2021-12-20T19:40:16.535039Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"markdown","source":"- ### Decision Tree","metadata":{}},{"cell_type":"code","source":"model=DecisionTreeRegressor(random_state=0)\nreg_func(model)","metadata":{"execution":{"iopub.status.busy":"2021-12-20T19:40:16.544796Z","iopub.execute_input":"2021-12-20T19:40:16.545799Z","iopub.status.idle":"2021-12-20T19:40:16.571668Z","shell.execute_reply.started":"2021-12-20T19:40:16.545738Z","shell.execute_reply":"2021-12-20T19:40:16.570614Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"markdown","source":"- ### Random Forest","metadata":{}},{"cell_type":"code","source":"\nregressor = RandomForestRegressor(n_estimators = 20, random_state = 0)\nreg_func(regressor)\n","metadata":{"execution":{"iopub.status.busy":"2021-12-20T19:40:16.576629Z","iopub.execute_input":"2021-12-20T19:40:16.577446Z","iopub.status.idle":"2021-12-20T19:40:16.666397Z","shell.execute_reply.started":"2021-12-20T19:40:16.577387Z","shell.execute_reply":"2021-12-20T19:40:16.665577Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"markdown","source":"- ### Extra Trees","metadata":{}},{"cell_type":"code","source":"model= ExtraTreesRegressor(n_estimators=20,random_state=0)\nreg_func(model)","metadata":{"execution":{"iopub.status.busy":"2021-12-20T19:40:16.667687Z","iopub.execute_input":"2021-12-20T19:40:16.668713Z","iopub.status.idle":"2021-12-20T19:40:16.706690Z","shell.execute_reply.started":"2021-12-20T19:40:16.668653Z","shell.execute_reply":"2021-12-20T19:40:16.705757Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"markdown","source":"- ### Bagging Regressor","metadata":{}},{"cell_type":"code","source":"model= BaggingRegressor(n_estimators=20,random_state=0)\nreg_func(model)","metadata":{"execution":{"iopub.status.busy":"2021-12-20T19:40:16.708068Z","iopub.execute_input":"2021-12-20T19:40:16.709415Z","iopub.status.idle":"2021-12-20T19:40:16.772062Z","shell.execute_reply.started":"2021-12-20T19:40:16.709353Z","shell.execute_reply":"2021-12-20T19:40:16.771348Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"markdown","source":"## Boosting Techniques","metadata":{}},{"cell_type":"markdown","source":"- ### ADABoost Regressor","metadata":{}},{"cell_type":"code","source":"model=AdaBoostRegressor(n_estimators=20,random_state=0)\nreg_func(model)","metadata":{"execution":{"iopub.status.busy":"2021-12-20T19:40:16.773001Z","iopub.execute_input":"2021-12-20T19:40:16.773741Z","iopub.status.idle":"2021-12-20T19:40:16.820209Z","shell.execute_reply.started":"2021-12-20T19:40:16.773704Z","shell.execute_reply":"2021-12-20T19:40:16.819381Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"markdown","source":"- ### XGBoost","metadata":{}},{"cell_type":"code","source":"xgb_r = xgb.XGBRegressor(n_estimators = 20, random_state= 0,gamma=1,subsample=0.1)\nreg_func(xgb_r)\n","metadata":{"execution":{"iopub.status.busy":"2021-12-20T19:40:16.821583Z","iopub.execute_input":"2021-12-20T19:40:16.821981Z","iopub.status.idle":"2021-12-20T19:40:16.903343Z","shell.execute_reply.started":"2021-12-20T19:40:16.821934Z","shell.execute_reply":"2021-12-20T19:40:16.902644Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"markdown","source":"- ### Gradient Boosting","metadata":{}},{"cell_type":"code","source":"model=GradientBoostingRegressor(n_estimators = 20, random_state= 0,learning_rate=0.1)\nreg_func(model)","metadata":{"execution":{"iopub.status.busy":"2021-12-20T19:40:16.907657Z","iopub.execute_input":"2021-12-20T19:40:16.909785Z","iopub.status.idle":"2021-12-20T19:40:16.927306Z","shell.execute_reply.started":"2021-12-20T19:40:16.909723Z","shell.execute_reply":"2021-12-20T19:40:16.926143Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"markdown","source":"- ## Evaluating Algorithms","metadata":{}},{"cell_type":"markdown","source":"- As shown above ``` Mean Squared Error``` is the lowest for the **XGBoost** algorithm with 0.024. Hence it is the best working model for this dataset\n- The highest loss is for **Decision Tree**, since the input data for prediction contains 95% categorical features this results in sparse data reducing the efficiency of the tree-based models. \n- This also explains why linear regression models have a range of MSE between 0.02-0.04, while tree-based models go upto 0.06.","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}}]}